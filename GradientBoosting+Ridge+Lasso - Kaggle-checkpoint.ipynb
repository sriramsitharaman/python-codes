{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import display\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Load data\n",
    "folder=\"C:\\\\Users\\\\sriram\\\\OneDrive\\\\Kaggle\\\\Home Price\\\\\"\n",
    "train = pd.read_csv(folder+\"Train_shah.csv\")\n",
    "test = pd.read_csv(folder+\"test_shah.csv\")\n",
    "\n",
    "# First look at the data\n",
    "print(train.shape)\n",
    "display(train.head())\n",
    "\n",
    "#NaN\n",
    "train.fillna(value=-999.0,inplace=True)\n",
    "test.fillna(value=-999.0,inplace=True)\n",
    "\n",
    "print('Type numeric:')\n",
    "list_feature_Nan = []\n",
    "for i in train.select_dtypes(exclude=['object']).columns:\n",
    "    if (train[i] == -999.0).astype(int).sum() > 0:\n",
    "        print(\"Feature: \", i, \"has\", round(((train[i] == -999.0).astype(int).sum()/1460)*100), \"% of NaN\")\n",
    "        list_feature_Nan.append(i)\n",
    "\n",
    "print('Type object:') \n",
    "\n",
    "for i in train.select_dtypes(include=['object']).columns:\n",
    "    if (train[i] == -999.0).astype(int).sum() > 0:\n",
    "        print(\"Feature: \", i, \"has\", round(((train[i] == -999.0).astype(int).sum()/1460)*100), \"% of NaN\") \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Replace numeric feature by mean\n",
    "#train_replace_mean = train\n",
    "#test_replace_mean = test\n",
    "\n",
    "for i in list_feature_Nan:\n",
    "    train[i].replace(-999.0,train[i].mean(),inplace=True)\n",
    "    test[i].replace(-999.0,train[i].mean(),inplace=True)\n",
    "\n",
    "#train = train[np.log(train['SalePrice'])<13.5]    \n",
    "#train = train[np.log(train['SalePrice'])>10.60]  \n",
    "#train.reset_index(inplace=True,drop=True)\n",
    "\n",
    "y = np.array(pd.DataFrame(np.log(train.SalePrice)))\n",
    "y2 = np.array(pd.DataFrame(np.log(train.SalePrice)))\n",
    "\n",
    "mean_saleprice = pd.DataFrame(train.groupby(['GrLivArea'])['LotArea'].mean())\n",
    "\n",
    "mean_saleprice.columns = ['LotArea_bis']\n",
    "train.drop('SalePrice',axis=1,inplace=True)    \n",
    "\n",
    "#log transform skewed numeric features:\n",
    "all_data = all_data = pd.concat((train.loc[:,'MSZoning':'soldage'],test.loc[:,'MSZoning':'soldage']))\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "print(skewed_feats)\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "print(skewed_feats)\n",
    "\n",
    "train[skewed_feats] = np.log1p(train[skewed_feats])\n",
    "test[skewed_feats] = np.log1p(test[skewed_feats])\n",
    "\n",
    "train[skewed_feats] = train[skewed_feats].fillna(all_data[skewed_feats].mean())\n",
    "test[skewed_feats] = test[skewed_feats].fillna(all_data[skewed_feats].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Label Encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "#Getting Categorical columns\n",
    "train_str = train.select_dtypes(include=['object'])\n",
    "test_str = test.select_dtypes(include=['object']) \n",
    "display(train_str.head())        \n",
    "\n",
    "print(train_str.columns.values)\n",
    "#Only numeric values\n",
    "train.drop(train_str.columns.values,axis=1,inplace=True)\n",
    "test.drop(train_str.columns.values,axis=1,inplace=True)\n",
    "print(train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_str_dum = pd.get_dummies(train_str)\n",
    "test_str_dum = pd.get_dummies(test_str)\n",
    "\n",
    "columns_dum = list(set(train_str_dum) & set(test_str_dum))\n",
    "\n",
    "train_str_dum = train_str_dum[columns_dum]\n",
    "test_str_dum = test_str_dum[columns_dum]\n",
    "\n",
    "#New train and New test\n",
    "train_flo = train.select_dtypes(exclude=['object'])\n",
    "test_flo = test.select_dtypes(exclude=['object']) \n",
    "\n",
    "new_train = pd.merge(train_flo,train_str_dum,left_index=True,right_index=True)\n",
    "new_test = pd.merge(test_flo,test_str_dum,left_index=True,right_index=True)\n",
    "\n",
    "display(new_train.head())\n",
    "print(new_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD, SparsePCA\n",
    "\n",
    "#train_clf = new_train.drop('SalePrice',axis=1)\n",
    "train_clf = new_train.copy()\n",
    "train_clf.drop('Id',axis=1,inplace=True)\n",
    "\n",
    "index = pd.DataFrame(test.Id,columns = ['Id'])\n",
    "test_clf = new_test.drop('Id',axis=1)\n",
    "\n",
    "train_clf2 = train_clf\n",
    "#train_clf2 = pd.merge(train_clf2,train[['LotFrontage','MasVnrArea','GarageYrBlt']],left_index=True,right_index=True)\n",
    "#train_clf2['tot_sf'] = train_clf2['TotalBsmtSF'] + train_clf2['GrLivArea']\n",
    "train_clf2['ratio_fl'] = train_clf2['X2ndFlrSF'] / train_clf2['X1stFlrSF'] \n",
    "#train_clf2['garage_ex'] = (train_clf2['GarageQual_Gd'] + train_clf2['GarageQual_TA']                            + train_clf2['GarageQual_Fa'] + train_clf2['GarageQual_Po']) * (train_clf2['GarageCond_Ex'])\n",
    "\n",
    "clus = KernelPCA(n_components = 25)\n",
    "train_clf2_pca = clus.fit_transform(train_clf2)\n",
    "train_clf3 = pd.merge(train_clf2,pd.DataFrame(train_clf2_pca),left_index=True,right_index=True)\n",
    "\n",
    "print(train_clf3.columns.values)\n",
    "test_clf2 = test_clf\n",
    "#test_clf2 = pd.merge(test_clf2,test[['LotFrontage','MasVnrArea','GarageYrBlt']],left_index=True,right_index=True)\n",
    "#test_clf2['tot_sf'] = test_clf2['TotalBsmtSF'] + test_clf2['GrLivArea']\n",
    "test_clf2['ratio_fl'] = test_clf2['X2ndFlrSF']  / test_clf2['X1stFlrSF']\n",
    "#test_clf2['garage_ex'] = (test_clf2['GarageQual_Gd'] + test_clf2['GarageQual_TA'] + test_clf2['GarageQual_Fa'] + test_clf2['GarageQual_Po']) * (test_clf2['GarageCond_Ex'])\n",
    "\n",
    "test_clf3 = pd.merge(test_clf2,pd.DataFrame(clus.transform(test_clf2)),left_index=True,right_index=True)\n",
    "\n",
    "index = pd.DataFrame(test.Id,columns = ['Id'])\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def score(clf, train_np, random_state, folds, target, length):\n",
    "    kf = KFold(n = length , n_folds=folds, shuffle = True, random_state = random_state)\n",
    "    for itrain, itest in kf:\n",
    "        Xtr, Xte = train_np[itrain], train_np[itest]\n",
    "        ytr, yte = target[itrain], target[itest]\n",
    "        clf.fit(Xtr, ytr.ravel())\n",
    "        pred = pd.DataFrame(clf.predict(Xte))\n",
    "        return rmse(yte, pred)\n",
    "    return rmse(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_clf2.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#Delete z_score > 4 feature = GrLivArea\n",
    "#z_score = pd.DataFrame(stats.zscore(pd.DataFrame(y), axis=1))\n",
    "#z_score.columns = train_clf3.columns\n",
    "#print(z_score[z_score['GrLivArea']>4].index)\n",
    "\n",
    "#train_clf4 = train_clf3.drop(train_clf3.index[z_score[z_score['GrLivArea']>4].index])\n",
    "#y_bis =  pd.DataFrame(y).drop(pd.DataFrame(y).index[z_score[z_score['GrLivArea']>4].index])\n",
    "#y_bis_array = np.array(y_bis)\n",
    "train_clf4 = train_clf2.copy()\n",
    "#train_clf4['LotArea'] = np.sqrt(train_clf3['LotArea'])\n",
    "\n",
    "#train_clf5 = train_clf3.copy()\n",
    "#train_clf5['LotArea'] = np.log1p(train_clf3['LotArea'])\n",
    "\n",
    "test_clf4 = test_clf2.copy()\n",
    "#test_clf4['LotArea'] = np.sqrt(test_clf3['LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in train_clf4.select_dtypes(include=['float64']).columns:\n",
    "    if train_clf4[i].min() > test_clf4[i].min():\n",
    "        train_clf4[i][train_clf4[i]==train_clf4[i].min()] = test_clf4[i].min()\n",
    "\n",
    "for i in train_clf4.select_dtypes(include=['float64']).columns:\n",
    "    if train_clf4[i].min() < test_clf4[i].min():\n",
    "        test_clf4[i][test_clf4[i]==test_clf4[i].min()] = train_clf4[i].min()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in train_clf4.select_dtypes(include=['float64']).columns:\n",
    "    if train_clf4[i].max() > test_clf4[i].max():\n",
    "        test_clf4[i][test_clf4[i]==test_clf4[i].max()] = train_clf4[i].max()\n",
    "\n",
    "for i in train_clf4.select_dtypes(include=['float64']).columns:\n",
    "    if train_clf4[i].max() < test_clf4[i].max():\n",
    "        train_clf4[i][train_clf4[i]==train_clf4[i].max()] = test_clf4[i].max()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def put_corr_feat(data,test,target):\n",
    "    data_new = data.copy()\n",
    "    test_new = test.copy()\n",
    "    for i in data.columns:\n",
    "        corr1=stats.pearsonr(np.array(pd.DataFrame(data[i])),target)[0]\n",
    "        corr2=stats.pearsonr(np.array(pd.DataFrame(data[i]**3)),target)[0]\n",
    "        if abs(corr2)>abs(corr1)*1.2:\n",
    "            print(i)\n",
    "            #print(data[i])\n",
    "            #print(abs(corr2),'VS',abs(corr1))\n",
    "            data_new[i]=np.array(data_new[i])**3\n",
    "            #print(data_new[i])\n",
    "            test_new[i]=np.array(test_new[i])**3\n",
    "    return data_new, test_new\n",
    "    \n",
    "data1, test1 = put_corr_feat(train_clf2,test_clf2,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import Ridge, LassoCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LarsCV\n",
    "\n",
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    a = []\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        a.append(i)\n",
    "        i += step\n",
    "    return a\n",
    "\n",
    "#Cs1 = list(range(2,10,1))\n",
    "#Cs1 = [15,16,17,18,19,20,21]\n",
    "Cs1 = [5000,6000,7000,8000,9000,10000]\n",
    "#Cs1 = [0.6,0.7,0.75,0.8,0.85,0.9]\n",
    "res = []\n",
    "res1 = []\n",
    "res2 = []\n",
    "res3 = []\n",
    "res4 = []\n",
    "Cs3=[]\n",
    "\n",
    "train_np = np.array(train_clf3)\n",
    "#train_np2 = np.array(data1)\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "#for C in Cs1:\n",
    "#    res1.append(score(xgb.XGBRegressor(n_estimators = C, seed = 0, learning_rate = 0.01, max_depth = 3, subsample = 0.8, colsample_bytree = 0.8, colsample_bylevel = 0.8 ),train_np,random_state = 0, folds = 7, target = y , length = 1450))\n",
    "#    res2.append(score(xgb.XGBRegressor(n_estimators = C, seed = 0, learning_rate = 0.01, max_depth = 3, subsample = 0.8, colsample_bytree = 0.8, colsample_bylevel = 0.8 ),train_np,random_state = 0, folds = 7, target = y , length = 1450))\n",
    "    #res3.append(score(LassoCV(alphas = [C, 1, 0.1, 0.01, 0.001, 0.0005]), train_np, random_state = 0, folds = 7, target = y , length = 1450))\n",
    "    #res4.append(score(LassoCV(alphas = [C, 1, 0.1, 0.01, 0.001, 0.0005]), train_np2, random_state = 0, folds = 7, target = y , length = 1450))\n",
    "    #res1.append(score(xgb.XGBRegressor(n_estimators = 100, seed = 0, learning_rate = 0.01, max_depth = 3, subsample = 0.8, colsample_bytree = 0.8, colsample_bylevel = 0.8 ),SelectKBest(f_regression, k = 268).fit_transform(train_np,y),random_state = 0, folds = 7, target = y , length = 1450))\n",
    "    #res2.append(score(GradientBoostingRegressor(n_estimators = 100,learning_rate=0.005, max_depth = 3, min_samples_split=800,min_samples_leaf = 40,max_features=230,subsample = 0.85,random_state = 0),train_np,random_state = 0, folds = 7, target = y , length = 1450))\n",
    "    #res3.append(score(xgb.XGBRegressor(n_estimators = C, seed = 0, learning_rate = 0.01, max_depth = 3, subsample = 0.8, colsample_bytree = 0.8, colsample_bylevel = 0.8 ),train_np,random_state = 0, folds = 7, target = y , length = 1450))\n",
    "    #res3.append(score(MLPRegressor(hidden_layer_sizes=(800, ), activation = 'logistic', random_state = 0),train_np,random_state = 0, folds = C, target = y , length = 1450))\n",
    "    #res4.append(score(ExtraTreesRegressor(n_estimators = 700,  max_depth = 12, min_samples_leaf = 5, random_state = 0),train_np,random_state = 0, folds = 7, target = y , length = 1450))\n",
    "    #res2.append(score(xgb.XGBRegressor(n_estimators = C, seed = 0, learning_rate = 0.01, max_depth = 3, subsample = 0.8, colsample_bytree = 0.8, colsample_bylevel = 0.8 ),SelectKBest(f_regression, k = 268).fit_transform(train_np,y),random_state = 0, folds = 7))\n",
    "#     res.append(score(LassoCV(alphas = [ 1, 0.1, 0.01, 0.001, 0.0005]),SelectKBest(f_regression, k = C).fit_transform(train_clf3,y),random_state = 0, folds = 7))\n",
    "#     res2.append(score(LassoCV(alphas = [ 1, 0.1, 0.01, 0.001, 0.0005]),train_clf3,random_state = 0, folds = 7))\n",
    "     #res2.append(score(LassoCV(alphas = [ 1, 0.1, 0.001, 0.0005]),SelectKBest(f_regression, k = 268).fit_transform(train_clf3,y),random_state = 0, folds = 7))\n",
    "#for C in Cs2:    \n",
    "#    res2.append(score(AdaBoostRegressor(n_estimators = C, random_state = 42, learning_rate = 0.01, base_estimator = xgb.XGBRegressor(max_depth = 8, seed = 0)),train_np,random_state = 0, folds = 10))\n",
    "\n",
    "#p1, = plt.plot(Cs1, res1,'r-o',label=\"V1\")\n",
    "#p2, = plt.plot(Cs1, res2,'b-o',label=\"V2\")\n",
    "#p3, = plt.plot(Cs1, res3,'g-o',label=\"V3\")\n",
    "#p4, = plt.plot(Cs1, res4,'y-o',label=\"V4\")\n",
    "#plt.legend([p1,p2])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = pd.DataFrame(test.Id,columns = ['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#clf = LassoCV(alphas = [ 1, 0.1, 0.001, 0.0005], max_iter = 1000)\n",
    "#clf = xgb.XGBRegressor(n_estimators = 5000, seed = 0, learning_rate = 0.01, max_depth = 3, subsample = 0.8, colsample_bytree = 0.8, colsample_bylevel = 0.8 )\n",
    "clf2 = Ridge(alpha=21)\n",
    "clf3 = LassoCV(alphas = [1, 0.1, 0.001, 0.0005])\n",
    "#clf4 = GradientBoostingRegressor(n_estimators = 6000,learning_rate=0.005, max_depth = 3, min_samples_split=800,min_samples_leaf = 40,max_features=230,subsample = 0.85,random_state = 0)\n",
    "#clf5 = RandomForestRegressor(n_estimators = 750, max_depth = 8, min_samples_leaf = 2, random_state = 0)\n",
    "#Select = SelectKBest(f_regression, k = 268)\n",
    "\n",
    "#train_fin = np.array(Select.fit_transform(train_clf4,y))\n",
    "#test_fin = np.array(Select.transform(test_clf4))\n",
    "\n",
    "train_fin_ridge = np.array(robust_scaler.fit_transform(train_clf2))\n",
    "test_fin_ridge = np.array(robust_scaler.transform(test_clf2))\n",
    "\n",
    "#kf1 = KFold(n = 1450 , n_folds=10, random_state=0, shuffle = True)\n",
    "#kf2 = KFold(n = 1450 , n_folds=39, random_state=0, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "Select = SelectKBest(f_regression)\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "clf = xgb.XGBRegressor(n_estimators = 5000, \n",
    "                       seed = 0, \n",
    "                       learning_rate = 0.01, \n",
    "                       max_depth = 3, \n",
    "                       subsample = 0.8, \n",
    "                       colsample_bytree = 0.8, \n",
    "                       colsample_bylevel = 0.8 )\n",
    "clf2 = Ridge(alpha=21)\n",
    "clf3 = LassoCV(alphas = [1, 0.1, 0.001, 0.0005])\n",
    "clf4=RandomForestRegressor(n_estimators=1000, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                           min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                           min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                           random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "param_grid_clf = [{'clf__n_estimators': [3000,4000,5000,6000],\n",
    "               'clf__learning_rate':[0.01,0.03,0.05,0.1,0.15,0.2],\n",
    "               'clf__max_depth':[3,5,7,10],\n",
    "               'Select__k':[125,150,175,200],\n",
    "                }]\n",
    "param_grid_clf2 = [{\n",
    "               'clf__alpha':[20,21,23,25,30],\n",
    "               'Select__k':[125,150,175,200],\n",
    "                }]\n",
    "param_grid_clf3 = [{\n",
    "               'Select__k':[125,150,175,200],\n",
    "                }]\n",
    "\n",
    "param_grid_clf4 = [{\n",
    "                'clf__n_estimators': [1000,2000,3000,4000,5000,6000],\n",
    "               'clf__min_samples_leaf':[1,2,3,5,10],\n",
    "               'clf__max_features':['auto', 'sqrt', 'log2'],\n",
    "               'Select__k':[125,150,175,200],\n",
    "                }]\n",
    "\n",
    "gb = Pipeline([('Select', SelectAtMostKBest()),\n",
    "                    ('clf', clf)])\n",
    "\n",
    "Rid = Pipeline([('Select', SelectAtMostKBest()),\n",
    "                     ('Scale',robust_scaler),\n",
    "                    ('clf', clf2)])\n",
    "Lasso = Pipeline([('Select', SelectAtMostKBest()),\n",
    "                     ('Scale',robust_scaler),\n",
    "                    ('clf', clf3)])\n",
    "rf = Pipeline([('Select', SelectAtMostKBest()),\n",
    "                    ('clf', clf4)])\n",
    "\n",
    "Modelxgb = GridSearchCV(gb, param_grid_clf, \n",
    "                           scoring='r2',\n",
    "                           cv=7, verbose=5,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "ModelRidge = GridSearchCV(Rid, param_grid_clf2, \n",
    "                           scoring='r2',\n",
    "                           cv=5, verbose=5,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "ModelLasso = GridSearchCV(Lasso, param_grid_clf3, \n",
    "                           scoring='r2',\n",
    "                           cv=5, verbose=5,\n",
    "                           n_jobs=-1)\n",
    "ModelRf = GridSearchCV(rf, param_grid_clf4, \n",
    "                           scoring='r2',\n",
    "                           cv=5, verbose=5,\n",
    "                           n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Modelxgb.fit(train_clf4,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Best parameter set: %s ' % Modelxgb.best_params_)\n",
    "print('CV Accuracy: %.3f' % Modelxgb.best_score_)\n",
    "Best = Modelxgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModelRidge.fit(train_fin_ridge,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Best parameter set: %s ' % ModelRidge.best_params_)\n",
    "print('CV Accuracy: %.3f' % ModelRidge.best_score_)\n",
    "Best1 = ModelRidge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModelLasso.fit(train_fin_ridge,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Best parameter set: %s ' % ModelLasso.best_params_)\n",
    "print('CV Accuracy: %.3f' % ModelLasso.best_score_)\n",
    "Best2 = ModelLasso.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ModelRf.fit(train_clf4,y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ForRandomForest\n",
    "print('Best parameter set: %s ' % ModelRf.best_params_)\n",
    "print('CV Accuracy: %.3f' % ModelRf.best_score_)\n",
    "Best3 = ModelRf.best_estimator_\n",
    "expPredRf=pd.DataFrame(Best3.predict(test_clf4))\n",
    "predRf=pd.DataFrame(np.exp(Best3.predict(test_clf4)))\n",
    "\n",
    "predRf_final = pd.DataFrame(predRf, index = new_test.index, columns = ['SalePrice'])\n",
    "#replace by mean\n",
    "for i in predRf_final[predRf_final.values<100].index.values:\n",
    "    predRf_final[predRf_final.index == i] = 180921.1959\n",
    "\n",
    "expPredRf_final = pd.DataFrame(expPredRf, index = new_test.index, columns = ['SalePrice'])\n",
    "predRf_final.to_csv(folder+'predRf_final.csv',index=False)\n",
    "expPredRf_final.to_csv(folder+'expPredRf_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ForGradientBoosting\n",
    "print('Best parameter set: %s ' % Modelxgb.best_params_)\n",
    "print('CV Accuracy: %.3f' % Modelxgb.best_score_)\n",
    "Best = Modelxgb.best_estimator_\n",
    "expPredGB=pd.DataFrame(Best.predict(test_clf4))\n",
    "predGB=pd.DataFrame(np.exp(Best.predict(test_clf4)))\n",
    "\n",
    "predGB_final = pd.DataFrame(predGB, index = new_test.index, columns = ['SalePrice'])\n",
    "#replace by mean\n",
    "for i in predGB_final[predGB_final.values<100].index.values:\n",
    "    predRf_final[predGB_final.index == i] = 180921.1959\n",
    "\n",
    "expPredGB_final = pd.DataFrame(expPredGB, index = new_test.index, columns = ['SalePrice'])\n",
    "predGB_final.to_csv(folder+'predGB_final.csv',index=False)\n",
    "expPredGB_final.to_csv(folder+'expPredGB_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder=\"C:\\\\Users\\\\sriram\\\\OneDrive\\\\Kaggle\\\\Home Price\\\\Submission\\\\Run2_04_12\\\\\"\n",
    "#clf2.fit(train_fin_ridge, y)\n",
    "pred2 = pd.DataFrame(Best1.predict(test_fin_ridge))\n",
    "        \n",
    "#clf3.fit(train_fin_ridge, y)\n",
    "pred3 = pd.DataFrame(Best2.predict(test_fin_ridge))\n",
    "\n",
    "\n",
    "pred1=pd.DataFrame(Best.predict(test_clf4))\n",
    "\n",
    "for i in pred2[np.exp(pred2).values<1].index.values:\n",
    "    pred2[pred2.index == i] = pred1[pred1.index == i]\n",
    "\n",
    "\n",
    "for i in pred2[pred2.values>12].index.values:\n",
    "    pred2[pred2.index == i] = pred1[pred1.index == i]\n",
    "\n",
    "print(pred_1.head())\n",
    "print(pred_2.head())\n",
    "print(pred_3.head())\n",
    "pred_1 = (pred1+2*pred2+pred3)/4\n",
    "pred_2 = (2*pred1+pred2+pred3)/4\n",
    "pred_3 = (pred1+pred2+2*pred3)/4\n",
    "\n",
    "\n",
    "\n",
    "pred_1.columns = ['SalePrice']\n",
    "pred_2.columns = ['SalePrice']\n",
    "pred_3.columns = ['SalePrice']\n",
    "\n",
    "pred_final_1 = pd.DataFrame(np.exp(pred_1), index = new_test.index, columns = ['SalePrice'])\n",
    "pred_final_2 = pd.DataFrame(np.exp(pred_2), index = new_test.index, columns = ['SalePrice'])\n",
    "pred_final_3 = pd.DataFrame(np.exp(pred_3), index = new_test.index, columns = ['SalePrice'])\n",
    "\n",
    "#replace by mean\n",
    "for i in pred_final_1[pred_final_1.values<100].index.values:\n",
    "    pred_final_1[pred_final_1.index == i] = 180921.1959\n",
    "#replace by mean\n",
    "for i in pred_final_2[pred_final_2.values<100].index.values:\n",
    "    pred_final_2[pred_final_2.index == i] = 180921.1959\n",
    "#replace by mean\n",
    "for i in pred_final_3[pred_final_3.values<100].index.values:\n",
    "    pred_final_3[pred_final_3.index == i] = 180921.1959\n",
    "\n",
    "print(pred_final_1.head())\n",
    "print(pred_final_2.head())\n",
    "print(pred_final_3.head())\n",
    "\n",
    "pred_final_1_submit = pd.merge(index,pred_final_1,left_index=True,right_index=True)\n",
    "pred_final_2_submit = pd.merge(index,pred_final_2,left_index=True,right_index=True)\n",
    "pred_final_3_submit = pd.merge(index,pred_final_3,left_index=True,right_index=True)\n",
    "\n",
    "pred_final_1_submit.to_csv(folder+'pred_final_1_submit_1.csv',index=False)\n",
    "pred_final_2_submit.to_csv(folder+'pred_final_2_submit_1.csv',index=False)\n",
    "pred_final_3_submit.to_csv(folder+'pred_final_3_submit_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "res1 = []\n",
    "res4 = []\n",
    "\n",
    "for itrain, itest in kf1:\n",
    "    i = i + 1\n",
    "    Xtr, Xte = train_fin[itrain], train_fin[itest]\n",
    "    ytr, yte = y[itrain], y[itest]\n",
    "    clf.fit(Xtr, ytr.ravel())\n",
    "    if i == 1:\n",
    "        pred1 = pd.DataFrame(clf.predict(test_fin))\n",
    "        print(\"Fold 1 :\", rmse(yte, pd.DataFrame(clf.predict(Xte))))\n",
    "        res1.append(rmse(yte, pd.DataFrame(clf.predict(Xte))))\n",
    "    if i > 1 :\n",
    "        pred1 = pred1 + pd.DataFrame(clf.predict(test_fin))\n",
    "        print(\"Fold \",i, \" :\", rmse(yte, pd.DataFrame(clf.predict(Xte))))\n",
    "        res1.append(rmse(yte, pd.DataFrame(clf.predict(Xte))))\n",
    "\n",
    "        \n",
    "#clf.fit(train_fin, y)\n",
    "#pred_1 = pd.DataFrame(clf.predict(test_fin))\n",
    "        \n",
    "clf2.fit(train_fin_ridge, y)\n",
    "pred2 = pd.DataFrame(clf2.predict(test_fin_ridge))\n",
    "        \n",
    "clf3.fit(train_fin_ridge, y)\n",
    "pred3 = pd.DataFrame(clf3.predict(test_fin_ridge))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print (pred1.head())\n",
    "print (pred2.head())\n",
    "pred_1 = pred1/10\n",
    "print (pred_1.head())\n",
    "\n",
    "for i in pred2[np.exp(pred2).values<1].index.values:\n",
    "    pred2[pred2.index == i] = pred_1[pred_1.index == i]\n",
    "\n",
    "\n",
    "for i in pred2[pred2.values>12].index.values:\n",
    "    pred2[pred2.index == i] = pred_1[pred_1.index == i]\n",
    "    \n",
    "print(np.mean(res1))\n",
    "\n",
    "pred_1 = (pred_1+2*pred2+pred3)/4\n",
    "pred_2 = (pred_1+pred3)/2\n",
    "pred_xg = pred_1\n",
    "print (pred_1.head())\n",
    "pred_1.columns = ['SalePrice']\n",
    "pred_2.columns = ['SalePrice']\n",
    "pred_xg.columns = ['SalePrice']\n",
    "pred3.columns = ['SalePrice']\n",
    "\n",
    "pred_final_1 = pd.DataFrame(np.exp(pred_1), index = new_test.index, columns = ['SalePrice'])\n",
    "pred_final_2 = pd.DataFrame(np.exp(pred_2), index = new_test.index, columns = ['SalePrice'])\n",
    "pred_Lasso = pd.DataFrame(np.exp(pred3), index = new_test.index, columns = ['SalePrice'])\n",
    "pred_xg = pd.DataFrame(np.exp(pred_xg), index = new_test.index, columns = ['SalePrice'])\n",
    "\n",
    "#replace by mean\n",
    "for i in pred_final_1[pred_final_1.values<100].index.values:\n",
    "    pred_final_1[pred_final_1.index == i] = 180921.1959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_final = pred_final_1\n",
    "\n",
    "pred_submit = pd.merge(index,pred_final,left_index=True,right_index=True)\n",
    "pred_Lasso_submit = pd.merge(index,pred_Lasso,left_index=True,right_index=True)\n",
    "pred_xg_submit = pd.merge(index,pred_xg,left_index=True,right_index=True)\n",
    "pred_xg_lasso_submit = pd.merge(index,pred_final_2,left_index=True,right_index=True)\n",
    "\n",
    "print(pred_xg_lasso_submit.head())\n",
    "Combined=(pred_1+pred_2+pred_Lasso+pred_xg)/4\n",
    "pred_submit.to_csv('XG_Ridge_Lasso.csv',index=False)\n",
    "pred_Lasso_submit.to_csv('Lasso.csv',index=False)\n",
    "pred_xg_submit.to_csv('XGB.csv',index=False)\n",
    "pred_xg_lasso_submit.to_csv('XGB_Lasso.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
