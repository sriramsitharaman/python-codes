{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "inputData = np.array(list(itertools.product([0, 1], repeat=4)))\n",
    "y=np.array([[0,1,1,0,1,0,0,1,1,0,0,1,0,1,1,0]])\n",
    "#bias=np.array([[1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-1*x))\n",
    "def sigmoidDer(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "def cost(m,n):\n",
    "    diff=[m[i]-n[i] for i in range(len(m))]\n",
    "    return 0.5*np.inner(diff,diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[1,2,3]\n",
    "b=[1.1,2,3]\n",
    "cost(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hiddenunits=4\n",
    "np.random.seed(1)\n",
    "weights1=2*np.random.random((Hiddenunits,len(inputData[0])+1)) - 1\n",
    "weights2=2*np.random.random(Hiddenunits+1) - 1\n",
    "#rows=units=weights1.shape[0]\n",
    "#cols=weights1.shape[1]\n",
    "#for i in range(rows):\n",
    "#    for j in range(cols):\n",
    "#        weights1[i][j]=np.random.uniform(-1, 1)\n",
    "#for j in range(Hiddenunits+1):    \n",
    "#    weights2[j]=np.random.uniform(-1, 1)\n",
    "\n",
    "print (\"Initial Weights\\n\")\n",
    "print(weights1,weights2)\n",
    "#Hidden unit output\n",
    "l1=np.zeros(Hiddenunits)\n",
    "DeltaW1=np.zeros(shape=(Hiddenunits,len(inputData[0])+1))\n",
    "DeltaW2=np.zeros(Hiddenunits+1)\n",
    "FirstAct=np.zeros(Hiddenunits)\n",
    "print(DeltaW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_list=[]\n",
    "start=0\n",
    "for i in range(10):\n",
    "    start+=0.05\n",
    "    n_list.append(start)\n",
    "\n",
    "print (n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n=0.5\n",
    "l2_errorList=[]\n",
    "CostEpoch=[]\n",
    "import time\n",
    "#outputFile=open(\"Results-momentum-notrandominputorder.csv\",\"w\")\n",
    "outputFile=open(\"check-1.csv\",\"w\")\n",
    "timearray=np.zeros(len(n_list))\n",
    "ConvIter=np.zeros(len(n_list))\n",
    "count=0\n",
    "mu=0.9\n",
    "from random import shuffle\n",
    "for n in sorted(n_list,reverse=True):\n",
    "    resultLine=[]\n",
    "    print (\"---------For learning rate \", n, \"---------\\n\")\n",
    "    resultLine.append(n)\n",
    "    np.random.seed(2)\n",
    "    weights1=2*np.random.random((Hiddenunits,len(inputData[0])+1)) - 1\n",
    "    weights2=2*np.random.random(Hiddenunits+1) - 1\n",
    "    start_time = time.time()\n",
    "    new2=np.zeros(4)\n",
    "    new1=np.zeros((4,5))\n",
    "    new20=0\n",
    "    CostEpoch=[]\n",
    "    for epoch in range(10000000):\n",
    "        predy=[]\n",
    "        l2_errors=0\n",
    "        x = [i for i in range(len(inputData))]\n",
    "        shuffle(x)\n",
    "        for row in x:\n",
    "            #print (\"Row\" , row , \"\\n\")\n",
    "            #print (inputData[row])\n",
    "            for unit in range(len(l1)):\n",
    "                v1=weights1[unit,0]+np.dot(inputData[row],weights1[unit,1:])\n",
    "                FirstAct[unit]=v1\n",
    "                #print (\"unit \",unit,\"Potential\",v1)\n",
    "                l1[unit]=sigmoid(v1)\n",
    "                #print (\"unit \",unit,\"Output\",v1,\"\\n\")\n",
    "            #print (l1)\n",
    "            v2=weights2[0]+np.dot(l1,weights2[1:])\n",
    "            l2=sigmoid(v2)\n",
    "            #print (l2)\n",
    "            predy.append(l2)\n",
    "            #l2=0 if v2<=5 else 1\n",
    "            l2_error=-1*(l2-y[0][row])\n",
    "            #print (l2_error)\n",
    "            delta2=l2_error*sigmoidDer(v2)\n",
    "            DeltaW2=np.dot(delta2,l1)\n",
    "            \n",
    "            for unit in range(len(l1)):\n",
    "                deltaw1=np.dot(delta2*sigmoidDer(FirstAct[unit]),weights2[unit+1])\n",
    "                #print (\"unit \",unit,\"deltaw1\",deltaw1)\n",
    "                new1[unit,0]=mu*new1[unit,0]+np.dot(n,deltaw1)\n",
    "                weights1[unit,0]+=new1[unit,0]\n",
    "                new1[unit,1:]=mu*new1[unit,1:]+np.dot(n*inputData[row],deltaw1)\n",
    "                weights1[unit,1:]+=new1[unit,1:]\n",
    "            \n",
    "            new20=mu*new20+n*delta2\n",
    "            new2=mu*new2+n*DeltaW2\n",
    "            weights2[0]+=new20\n",
    "            weights2[1:]+=new2\n",
    "            l2_errors+=0 if abs(l2_error)<=0.05 else 1\n",
    "        l2_errorList.append(l2_errors)\n",
    "        cost1=cost(predy,y[0])\n",
    "        CostEpoch.append(cost1)\n",
    "        if epoch%50000==0:\n",
    "            print (epoch,l2_errors)\n",
    "        if l2_errors==0:\n",
    "            print (\"No Errors @Iteration \", epoch)\n",
    "            ConvIter[count]=epoch\n",
    "            resultLine.append(epoch)\n",
    "            duration=time.time()-start_time\n",
    "            timearray[count]=duration\n",
    "            resultLine.append(duration)\n",
    "            resultLine=resultLine+list(weights1.reshape((20,)))+list(weights2)\n",
    "            outputFile.write(\",\".join([str(i) for i in resultLine])+\"\\n\")\n",
    "            count+=1\n",
    "            print(plt.plot(CostEpoch))\n",
    "            break\n",
    "\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(CostEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(plt.plot(np.log(CostEpoch[3000:3456])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Output Check\n",
    "for row in range(len(inputData)):\n",
    "    for unit in range(len(l1)):\n",
    "        v1=weights1[unit,0]+np.dot(inputData[row],weights1[unit,1:])\n",
    "        FirstAct[unit]=v1\n",
    "        l1[unit]=sigmoid(v1)\n",
    "    #print (l1)\n",
    "    v2=weights2[0]+np.dot(l1,weights2[1:])\n",
    "    #print (v2)\n",
    "    l2=sigmoid(v2)\n",
    "    print(y[0][row],l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Without Momentum\n",
    "#n=0.5\n",
    "l2_errorList=[]\n",
    "CostEpoch=[]\n",
    "import time\n",
    "\n",
    "timearray=np.zeros(len(n_list))\n",
    "ConvIter=np.zeros(len(n_list))\n",
    "count=0\n",
    "from random import shuffle\n",
    "for n in n_list:\n",
    "    weights1=2*np.random.random((Hiddenunits,len(inputData[0])+1)) - 1\n",
    "    weights2=2*np.random.random(Hiddenunits+1) - 1\n",
    "    start_time = time.time()\n",
    "    for epoch in range(10000000):\n",
    "        predy=[]\n",
    "        l2_errors=0\n",
    "        x = [i for i in range(len(inputData))]\n",
    "        shuffle(x)\n",
    "        for row in x:\n",
    "            #print (\"Row\" , row , \"\\n\")\n",
    "            #print (inputData[row])\n",
    "            for unit in range(len(l1)):\n",
    "                v1=weights1[unit,0]+np.dot(inputData[row],weights1[unit,1:])\n",
    "                FirstAct[unit]=v1\n",
    "                #print (\"unit \",unit,\"Potential\",v1)\n",
    "                l1[unit]=sigmoid(v1)\n",
    "                #print (\"unit \",unit,\"Output\",v1,\"\\n\")\n",
    "            #print (l1)\n",
    "            v2=weights2[0]+np.dot(l1,weights2[1:])\n",
    "            l2=sigmoid(v2)\n",
    "            #print (l2)\n",
    "            predy.append(l2)\n",
    "            #l2=0 if v2<=5 else 1\n",
    "            l2_error=-1*(l2-y[0][row])\n",
    "            #print (l2_error)\n",
    "            delta2=l2_error*sigmoidDer(v2)\n",
    "            DeltaW2=np.dot(delta2,l1)\n",
    "    \n",
    "            for unit in range(len(l1)):\n",
    "                deltaw1=np.dot(delta2*sigmoidDer(FirstAct[unit]),weights2[unit+1])\n",
    "                #print (\"unit \",unit,\"deltaw1\",deltaw1)\n",
    "                weights1[unit,0]+=np.dot(n,deltaw1)\n",
    "                weights1[unit,1:]+=np.dot(n*inputData[row],deltaw1)\n",
    "    \n",
    "            weights2[0]+=n*delta2\n",
    "            weights2[1:]+=n*DeltaW2\n",
    "            l2_errors+=0 if abs(l2_error)<=0.05 else 1\n",
    "        l2_errorList.append(l2_errors)\n",
    "        cost1=cost(predy,y[0])\n",
    "        CostEpoch.append(cost1)\n",
    "        if epoch%100000==0:\n",
    "            print (epoch,cost1)\n",
    "        if l2_errors==0:\n",
    "            print (\"No Errors @Iteration \", epoch)\n",
    "            ConvIter[count]=epoch\n",
    "            timearray[count]=time.time()-start_time\n",
    "            count+=1\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "from random import shuffle\n",
    "#Input Data\n",
    "inputData = np.array(list(itertools.product([0, 1], repeat=4)))\n",
    "#Output Data\n",
    "y=np.array([[0,1,1,0,1,0,0,1,1,0,0,1,0,1,1,0]])\n",
    "\n",
    "\n",
    "#Sigmoid Activation Function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-1*x))\n",
    "\n",
    "#Sigmoid Activation Function derivative\n",
    "def sigmoidDer(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\t\n",
    "#Cost Function\n",
    "def cost(m,n):\n",
    "    diff=[m[i]-n[i] for i in range(len(m))]\n",
    "    return 0.5*np.inner(diff,diff)\n",
    "\t\n",
    "Hiddenunits=4\n",
    "#Hidden unit output\n",
    "l1=np.zeros(Hiddenunits)\n",
    "DeltaW1=np.zeros(shape=(Hiddenunits,len(inputData[0])+1))\n",
    "DeltaW2=np.zeros(Hiddenunits+1)\n",
    "FirstAct=np.zeros(Hiddenunits)\n",
    "#List of learning rate values from 0.05 to 0.5\n",
    "n_list=[]\n",
    "start=0\n",
    "for i in range(10):\n",
    "    start+=0.05\n",
    "    n_list.append(start)\n",
    "\n",
    "\n",
    "l2_errorList=[]\n",
    "CostEpoch=[]\n",
    "#outputFile=open(\"Results-momentum-notrandominputorder.csv\",\"w\")\n",
    "#Define the location of the outputFile here\n",
    "outputFile=open(\"Output.csv\",\"w\")\n",
    "timearray=np.zeros(len(n_list))\n",
    "ConvIter=np.zeros(len(n_list))\n",
    "count=0\n",
    "mu=0.9\n",
    "\n",
    "for n in sorted(n_list,reverse=True):\n",
    "    resultLine=[]\n",
    "    print (\"---------For learning rate \", n, \"---------\\n\")\n",
    "    resultLine.append(n)\n",
    "    np.random.seed(1)\n",
    "    weights1=2*np.random.random((Hiddenunits,len(inputData[0])+1)) - 1\n",
    "    weights2=2*np.random.random(Hiddenunits+1) - 1\n",
    "    start_time = time.time()\n",
    "    new2=np.zeros(4)\n",
    "    new1=np.zeros((4,5))\n",
    "    new20=0\n",
    "    CostEpoch=[]\n",
    "    for epoch in range(10000000):\n",
    "        predy=[]\n",
    "        l2_errors=0\n",
    "        x = [i for i in range(len(inputData))]\n",
    "\t\t#Remove the comment in the next line to activate the shuffled Input\n",
    "        #shuffle(x)\n",
    "        for row in x:\n",
    "            #print (\"Row\" , row , \"\\n\")\n",
    "            #print (inputData[row])\n",
    "            for unit in range(len(l1)):\n",
    "                v1=weights1[unit,0]+np.dot(inputData[row],weights1[unit,1:])\n",
    "                FirstAct[unit]=v1\n",
    "                #print (\"unit \",unit,\"Potential\",v1)\n",
    "                l1[unit]=sigmoid(v1)\n",
    "                #print (\"unit \",unit,\"Output\",v1,\"\\n\")\n",
    "            #print (l1)\n",
    "            v2=weights2[0]+np.dot(l1,weights2[1:])\n",
    "            l2=sigmoid(v2)\n",
    "            #print (l2)\n",
    "            predy.append(l2)\n",
    "            #l2=0 if v2<=5 else 1\n",
    "            l2_error=-1*(l2-y[0][row])\n",
    "            #print (l2_error)\n",
    "            delta2=l2_error*sigmoidDer(v2)\n",
    "            DeltaW2=np.dot(delta2,l1)\n",
    "            \n",
    "            for unit in range(len(l1)):\n",
    "                deltaw1=np.dot(delta2*sigmoidDer(FirstAct[unit]),weights2[unit+1])\n",
    "                #print (\"unit \",unit,\"deltaw1\",deltaw1)\n",
    "                new1[unit,0]=mu*new1[unit,0]+np.dot(n,deltaw1)\n",
    "                weights1[unit,0]+=new1[unit,0]\n",
    "                new1[unit,1:]=mu*new1[unit,1:]+np.dot(n*inputData[row],deltaw1)\n",
    "                weights1[unit,1:]+=new1[unit,1:]\n",
    "            \n",
    "            new20=mu*new20+n*delta2\n",
    "            new2=mu*new2+n*DeltaW2\n",
    "            weights2[0]+=new20\n",
    "            weights2[1:]+=new2\n",
    "            l2_errors+=0 if abs(l2_error)<=0.05 else 1\n",
    "        l2_errorList.append(l2_errors)\n",
    "        cost1=cost(predy,y[0])\n",
    "        CostEpoch.append(cost1)\n",
    "        if epoch%50000==0:\n",
    "            print (epoch,l2_errors)\n",
    "        if l2_errors==0:\n",
    "            print (\"No Errors @Iteration \", epoch)\n",
    "            ConvIter[count]=epoch\n",
    "            resultLine.append(epoch)\n",
    "            duration=time.time()-start_time\n",
    "            timearray[count]=duration\n",
    "            resultLine.append(duration)\n",
    "            resultLine=resultLine+list(weights1.reshape((20,)))+list(weights2)\n",
    "            outputFile.write(\",\".join([str(i) for i in resultLine])+\"\\n\")\n",
    "            count+=1\n",
    "            break\n",
    "\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class country:\n",
    "    gdp=\"334\"\n",
    "    def printgdp():\n",
    "        print(Self.gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usa=country()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "printgdp() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8f4eca56420d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0musa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintgdp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: printgdp() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "usa.printgdp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value of N:10\n",
      "[8, 6, 1, 10, 9, 2, 5, 3, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (numList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value of N:10\n",
      "Enter the value of x:45\n",
      "Mean:  38.499938\n",
      "SD  :  6.3622855953\n",
      "Probility that it is greater than  45   0.141129\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "N=int(input(\"Enter the value of N:\"))\n",
    "X=int(input(\"Enter the value of x:\"))\n",
    "TotalPaymentList=[]\n",
    "#Loop to generate the distribution of TotalPayments\n",
    "for i in range(1000000):    \n",
    "    numList=[i for i in range(1,N+1)]\n",
    "    shuffle(numList)\n",
    "    TotalPayment=numList[0]\n",
    "    for i in range(1,N):\n",
    "        TotalPayment+=abs(numList[i-1]-numList[i])\n",
    "    TotalPaymentList.append(TotalPayment)\n",
    "    \n",
    "print (\"Mean: \",np.mean(TotalPaymentList))\n",
    "print (\"SD  : \",np.std(TotalPaymentList))\n",
    "print (\"Probility that it is greater than \", X, \" \",sum(np.array(TotalPaymentList)>X)/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value of N:20\n",
      "For finding the prob that totalpayments value greater than a number X \n",
      "\n",
      "Enter the value of x:160\n",
      "Mean:  143.483442\n",
      "SD  :  18.4230536511\n",
      "Probility that it is greater than  160   0.182116\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "N=int(input(\"Enter the value of N:\"))\n",
    "print(\"For finding the prob that totalpayments value greater than a number X \\n\")\n",
    "X=int(input(\"Enter the value of x:\"))\n",
    "TotalPaymentList=[]\n",
    "#Loop to generate the distribution of TotalPayments\n",
    "for i in range(1000000):    \n",
    "    numList=[i for i in range(1,N+1)]\n",
    "    shuffle(numList)\n",
    "    TotalPayment=numList[0]\n",
    "    for i in range(1,N):\n",
    "        TotalPayment+=abs(numList[i-1]-numList[i])\n",
    "    TotalPaymentList.append(TotalPayment)\n",
    "    \n",
    "print (\"Mean: \",np.mean(TotalPaymentList))\n",
    "print (\"SD  : \",np.std(TotalPaymentList))\n",
    "print (\"Probility that it is greater than \", X, \" \",sum(np.array(TotalPaymentList)>X)/1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1537,1540,1542,1561,1575,1606,1614,1615,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file=\"C:\\\\Users\\\\sriram\\\\Desktop\\\\Data Incubator\\\\CollegeScorecard_Raw_Data\\\\CollegeScorecard_Raw_Data\\\\MERGED2013_14_PP.csv\"\n",
    "data2013=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7804, 1743)\n",
      "   UNITID    OPEID  OPEID6                               INSTNM        CITY  \\\n",
      "0  100654   100200    1002             Alabama A & M University      Normal   \n",
      "1  100663   105200    1052  University of Alabama at Birmingham  Birmingham   \n",
      "2  100690  2503400   25034                   Amridge University  Montgomery   \n",
      "3  100706   105500    1055  University of Alabama in Huntsville  Huntsville   \n",
      "4  100724   100500    1005             Alabama State University  Montgomery   \n",
      "\n",
      "  STABBR         ZIP  ACCREDAGENCY  INSTURL  NPCURL     ...      D100_L4  \\\n",
      "0     AL       35762           NaN      NaN     NaN     ...          NaN   \n",
      "1     AL  35294-0110           NaN      NaN     NaN     ...          NaN   \n",
      "2     AL  36117-3553           NaN      NaN     NaN     ...          NaN   \n",
      "3     AL       35899           NaN      NaN     NaN     ...          NaN   \n",
      "4     AL  36104-0271           NaN      NaN     NaN     ...          NaN   \n",
      "\n",
      "   TRANS_4  DTRANS_4  TRANS_L4  DTRANS_L4  ICLEVEL  UGDS_MEN  UGDS_WOMEN  \\\n",
      "0   0.2234     882.0       NaN        NaN        1    0.4861      0.5139   \n",
      "1   0.2358    1378.0       NaN        NaN        1    0.4135      0.5865   \n",
      "2   0.0000       3.0       NaN        NaN        1    0.3913      0.6087   \n",
      "3   0.3136     759.0       NaN        NaN        1    0.5580      0.4420   \n",
      "4   0.0000    1351.0       NaN        NaN        1    0.4085      0.5915   \n",
      "\n",
      "   CDR3_DENOM  CDR2_DENOM  \n",
      "0      1573.0         NaN  \n",
      "1      3475.0         NaN  \n",
      "2       336.0         NaN  \n",
      "3      1392.0         NaN  \n",
      "4      1960.0         NaN  \n",
      "\n",
      "[5 rows x 1743 columns]\n",
      "['UNITID' 'OPEID' 'OPEID6' ..., 'UGDS_WOMEN' 'CDR3_DENOM' 'CDR2_DENOM']\n"
     ]
    }
   ],
   "source": [
    "print(data2013.shape)\n",
    "print (data2013.head())\n",
    "print (data2013.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "satcols=[]\n",
    "for i in data2013.columns.values:\n",
    "    if \"sat\" in i.lower():\n",
    "        satcols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2013.columns.values[data2013.dtypes!='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=data2013[data2013['PREDDEG']==3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sat_Avg=x['SAT_AVG']\n",
    "admitted=x['UGDS']/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904.00552226638047"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.nansum(sat_Avg*admitted)/np.nansum(admitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     823.0\n",
      "1    1146.0\n",
      "2       NaN\n",
      "3    1180.0\n",
      "4     830.0\n",
      "Name: SAT_AVG, dtype: float64 0     4051.0\n",
      "1    11200.0\n",
      "2      322.0\n",
      "3     5525.0\n",
      "4     5354.0\n",
      "Name: UGDS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x['SAT_AVG'].head(),x['UGDS'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     833493.25\n",
       "1    3208800.00\n",
       "2           NaN\n",
       "3    1629875.00\n",
       "4    1110955.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADM_RATE,UGDS,SAT_AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833493.25"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "823*4051/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retentionRate=x['RET_FT4']\n",
    "afterone=admitted*retentionRate\n",
    "aftertwo=afterone*retentionRate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.59034031],\n",
       "       [ 0.59034031,  1.        ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_Avg=sat_Avg.fillna(0)\n",
    "#Percent still enrolled at original institution within 2 years 'ENRL_ORIG_YR2_RT'\n",
    "loc=list(x.columns.values).index('ENRL_ORIG_YR2_RT')\n",
    "afterTwoEnrolled=pd.to_numeric(x.iloc[:, loc], errors='coerce').fillna(0)\n",
    "check=pd.isnull(x.iloc[:, loc])\n",
    "#afterTwoEnrolled=x['ENRL_ORIG_YR2_RT']\n",
    "#afterTwoEnrolled=afterTwoEnrolled.fillna(0)\n",
    "np.corrcoef(sat_Avg[check==False],afterTwoEnrolled[check==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2276"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(check==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2276"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q3Cols=['LO_INC_COMP_ORIG_YR4_RT','MD_INC_COMP_ORIG_YR4_RT','HI_INC_COMP_ORIG_YR4_RT']\n",
    "xq3=x[Q3Cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LO_INC_COMP_ORIG_YR4_RT</th>\n",
       "      <th>MD_INC_COMP_ORIG_YR4_RT</th>\n",
       "      <th>HI_INC_COMP_ORIG_YR4_RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2216288385</td>\n",
       "      <td>0.2607361963</td>\n",
       "      <td>0.2912087912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3996212121</td>\n",
       "      <td>0.4238683128</td>\n",
       "      <td>0.4823717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2051282051</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "      <td>PrivacySuppressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3601286174</td>\n",
       "      <td>0.426035503</td>\n",
       "      <td>0.4159779614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1603119584</td>\n",
       "      <td>0.2211981567</td>\n",
       "      <td>0.299270073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LO_INC_COMP_ORIG_YR4_RT MD_INC_COMP_ORIG_YR4_RT HI_INC_COMP_ORIG_YR4_RT\n",
       "0            0.2216288385            0.2607361963            0.2912087912\n",
       "1            0.3996212121            0.4238683128            0.4823717949\n",
       "2            0.2051282051       PrivacySuppressed       PrivacySuppressed\n",
       "3            0.3601286174             0.426035503            0.4159779614\n",
       "4            0.1603119584            0.2211981567             0.299270073"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x == 'PrivacySuppressed': return 1\n",
    "    else: return 0\n",
    "\n",
    "check=xq3.applymap(f).sum(axis=1)\n",
    "\n",
    "xq3=xq3[check==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowInc=xq3['LO_INC_COMP_ORIG_YR4_RT'].apply(pd.to_numeric)\n",
    "highInc=xq3['HI_INC_COMP_ORIG_YR4_RT'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1138356408470725"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lowInc-highInc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_ind_from_stats\n",
    "from scipy.special import stdtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttest_ind:            t = nan  p = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1748: RuntimeWarning: invalid value encountered in greater\n",
      "  cond1 = (scale > 0) & (x > self.a) & (x < self.b)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1748: RuntimeWarning: invalid value encountered in less\n",
      "  cond1 = (scale > 0) & (x > self.a) & (x < self.b)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1749: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "t, p = ttest_ind(lowInc, highInc, equal_var=True)\n",
    "print(\"ttest_ind:            t = %g  p = %g\" % (t, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(highInc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the descriptive statistics of a and b.\n",
    "abar = lowInc.mean()\n",
    "avar = lowInc.var(ddof=1)\n",
    "na = lowInc.size\n",
    "adof = na - 1\n",
    "\n",
    "bbar = highInc.mean()\n",
    "bvar = highInc.var(ddof=1)\n",
    "nb = highInc.size\n",
    "bdof = nb - 1\n",
    "# Use the formulas directly.\n",
    "tf = (abar - bbar) / np.sqrt(avar/na + bvar/nb)\n",
    "dof = (avar/na + bvar/nb)**2 / (avar**2/(na**2*adof) + bvar**2/(nb**2*bdof))\n",
    "pf = 2*stdtr(dof, -np.abs(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.163264656171034"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3466.414973728392"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-77.155493452721245"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UGDS_WHITE    3670.5867\n",
       "UGDS_BLACK    1328.7039\n",
       "UGDS_HISP     1111.1291\n",
       "UGDS_ASIAN     231.9894\n",
       "UGDS_AIAN       98.0208\n",
       "UGDS_NHPI       31.7182\n",
       "UGDS_NRA       104.1167\n",
       "UGDS_UNKN      349.4508\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethinicCols=['UGDS_WHITE','UGDS_BLACK','UGDS_HISP','UGDS_ASIAN','UGDS_AIAN','UGDS_NHPI','UGDS_NRA','UGDS_UNKN']\n",
    "ethinicity=data2013[ethinicCols]\n",
    "ethinicity.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x>0: return 1\n",
    "    else: return 0\n",
    "\n",
    "check=ethinicity.applymap(f).sum(axis=1)\n",
    "\n",
    "ethinicFinal=ethinicity[check!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UGDS_WHITE</th>\n",
       "      <th>UGDS_BLACK</th>\n",
       "      <th>UGDS_HISP</th>\n",
       "      <th>UGDS_ASIAN</th>\n",
       "      <th>UGDS_AIAN</th>\n",
       "      <th>UGDS_NHPI</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5987</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2919</td>\n",
       "      <td>0.4224</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UGDS_WHITE  UGDS_BLACK  UGDS_HISP  UGDS_ASIAN  UGDS_AIAN  UGDS_NHPI  \\\n",
       "0      0.0279      0.9501     0.0089      0.0022     0.0012     0.0010   \n",
       "1      0.5987      0.2590     0.0258      0.0518     0.0026     0.0007   \n",
       "2      0.2919      0.4224     0.0093      0.0031     0.0031     0.0031   \n",
       "3      0.7012      0.1310     0.0338      0.0364     0.0145     0.0002   \n",
       "4      0.0161      0.9285     0.0114      0.0015     0.0009     0.0007   \n",
       "\n",
       "   UGDS_NRA  UGDS_UNKN  \n",
       "0    0.0002     0.0084  \n",
       "1    0.0140     0.0130  \n",
       "2    0.0000     0.2671  \n",
       "3    0.0329     0.0338  \n",
       "4    0.0207     0.0138  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethinicFinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1595"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethinicFinal['max']=ethinicFinal.max(axis=1)\n",
    "ethinicFinal['min']=ethinicFinal.min(axis=1)\n",
    "ethinicFinal['diversity']=ethinicFinal['max']-ethinicFinal['min']\n",
    "ethinicFinal['diversity'].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2001_02_PP.csv', '2002_03_PP.csv', '2003_04_PP.csv', '2004_05_PP.csv', '2005_06_PP.csv', '2006_07_PP.csv', '2007_08_PP.csv', '2008_09_PP.csv', '2009_10_PP.csv', '2010_11_PP.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1,6,442,451,598,607,611,620,624,633,789,802,806,815,893,906,971,984,997,1153,1166,1407,1408,1411,1425,1431,1432,1433,1437,1438,1439,1440,1445,1446,1447,1451,1452,1453,1454,1459,1460,1461,1465,1466,1467,1468,1473,1474,1475,1479,1480,1481,1482,1487,1488,1489,1501,1502,1537,1538,1539,1540,1541,1542,1603,1606,1609,1610,1611,1613,1614,1615,1616,1688,1689,1690,1691,1692,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1,6,1408,1431,1432,1433,1475,1489,1537,1538,1539,1540,1542,1603,1606,1610,1611,1614,1615,1616,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1,1447,1537,1540,1542,1606,1614,1615) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1,1537,1540,1542,1606,1614,1615) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1,6,1461,1561,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "folder=\"C:\\\\Users\\\\sriram\\\\Desktop\\\\Data Incubator\\\\CollegeScorecard_Raw_Data\\\\CollegeScorecard_Raw_Data\\\\MERGED\"\n",
    "#UGDS_WOMEN\n",
    "fileList=[]\n",
    "for i in range(2001,2011):\n",
    "    fileList.append(str(i)+\"_\"+str(i+1)[2:]+\"_PP.csv\")\n",
    "\n",
    "print (fileList)\n",
    "count=0\n",
    "for file in fileList:\n",
    "    try:\n",
    "        data1=pd.read_csv(folder+file,encoding='utf-8')\n",
    "    except:\n",
    "        continue\n",
    "    if count>0:\n",
    "        data10 = data10.append(data1, ignore_index=True)\n",
    "    else:\n",
    "        data10=data1\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68510, 1743)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5732395864388005"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalStudents=data10['UGDS']\n",
    "Women=data10['UGDS_WOMEN']\n",
    "totalWomen=totalStudents*Women\n",
    "np.sum(totalWomen)/np.sum(totalStudents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1995_96_PP.csv', '1996_97_PP.csv', '1997_98_PP.csv', '1998_99_PP.csv', '1999_00_PP.csv', '2000_01_PP.csv', '2001_02_PP.csv', '2002_03_PP.csv', '2003_04_PP.csv', '2004_05_PP.csv', '2005_06_PP.csv', '2006_07_PP.csv', '2007_08_PP.csv', '2008_09_PP.csv', '2009_10_PP.csv', '2010_11_PP.csv', '2011_12_PP.csv', '2012_13_PP.csv', '2013_14_PP.csv', '2014_15_PP.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#UGDS_WOMEN\n",
    "fileList=[]\n",
    "for i in range(1995,2015):\n",
    "    fileList.append(str(i)+\"_\"+str(i+1)[2:]+\"_PP.csv\")\n",
    "\n",
    "print (fileList)\n",
    "count=0\n",
    "for file in fileList:\n",
    "    try:\n",
    "        data1=pd.read_csv(folder+file,encoding='utf-8')\n",
    "    except:\n",
    "        continue\n",
    "    if count>0:\n",
    "        dataAll = dataAll.append(data1, ignore_index=True)\n",
    "    else:\n",
    "        dataAll=data1\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "folder=\"C:\\\\Users\\\\sriram\\\\Desktop\\\\Data Incubator\\\\CollegeScorecard_Raw_Data\\\\CollegeScorecard_Raw_Data\\\\MERGED\"\n",
    "finalData='2014_15_PP.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (6,9,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1411,1425,1427,1503,1517,1529,1530,1532,1537,1540,1541,1542,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1605,1606,1609,1610,1613,1614,1615,1725,1726,1727,1728,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataFinal=pd.read_csv(folder+finalData,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   REGION     value\n",
      "0       0  0.000000\n",
      "1       1  0.343891\n",
      "2       2  0.391709\n",
      "3       3  0.371404\n",
      "4       4  0.441931\n",
      "5       5  0.448148\n",
      "6       6  0.590743\n",
      "7       7  0.505051\n",
      "8       8  0.557780\n",
      "9       9  0.496894\n",
      "0.590742996346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#0\tU.S. Service Schools\tIPEDS\n",
    "#1\tNew England (CT, ME, MA, NH, RI, VT)\t\n",
    "#2\tMid East (DE, DC, MD, NJ, NY, PA)\t\n",
    "#3\tGreat Lakes (IL, IN, MI, OH, WI)\t\n",
    "#4\tPlains (IA, KS, MN, MO, NE, ND, SD)\t\n",
    "#5\tSoutheast (AL, AR, FL, GA, KY, LA, MS, NC, SC, TN, VA, WV)\t\n",
    "#6\tSouthwest (AZ, NM, OK, TX)\t\n",
    "#7\tRocky Mountains (CO, ID, MT, UT, WY)\t\n",
    "#8\tFar West (AK, CA, HI, NV, OR, WA)\t\n",
    "#9\tOutlying Areas (AS, FM, GU, MH, MP, PR, PW, VI)\t\n",
    "\n",
    "def f(x):\n",
    "    if x>=11 and x<=13: return 1\n",
    "    else: return 0\n",
    "\n",
    "\n",
    "\n",
    "q7data=dataFinal[['REGION','LOCALE']]\n",
    "q7data['city_0_1']=q7data.applymap(f)['LOCALE']\n",
    "output=pd.DataFrame({'value' : q7data.groupby( [\"REGION\"])['city_0_1'].mean()}).reset_index()\n",
    "print (output)\n",
    "print (max(output['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder=\"C:\\\\Users\\\\sriram\\\\Documents\\\\GitHub\\\\fnc-1\\\\\"\n",
    "bodies=pd.read_csv(folder+\"train_bodies.csv\")\n",
    "stances=pd.read_csv(folder+\"train_stances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>49972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "      <td>49972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>49972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>49972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "      <td>49972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  \\\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated   \n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree   \n",
       "\n",
       "     len  \n",
       "0  49972  \n",
       "1  49972  \n",
       "2  49972  \n",
       "3  49972  \n",
       "4  49972  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>len</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>115</td>\n",
       "      <td>Danny Boyle is directing the untitled film\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "      <td>65</td>\n",
       "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>91</td>\n",
       "      <td>30-year-old Moscow resident was hospitalized w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>82</td>\n",
       "      <td>(Reuters) - A Canadian soldier was shot at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "      <td>63</td>\n",
       "      <td>Fear not arachnophobes, the story of Bunbury's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  len  \\\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated  115   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree   65   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated   91   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated   82   \n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree   63   \n",
       "\n",
       "                                         articleBody  \n",
       "0  Danny Boyle is directing the untitled film\\r\\n...  \n",
       "1  Hundreds of Palestinians were evacuated from t...  \n",
       "2  30-year-old Moscow resident was hospitalized w...  \n",
       "3  (Reuters) - A Canadian soldier was shot at the...  \n",
       "4  Fear not arachnophobes, the story of Bunbury's...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return len(str(x))\n",
    "\n",
    "stances['len']=stances.applymap(f)['Headline']\n",
    "final=pd.merge(stances, bodies, how='left',left_on=\"Body ID\",right_on=\"Body ID\")\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Wordcloud:\n",
    "\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "    #d = path.dirname(__file__)\n",
    "def createwordcloud(data):  \n",
    "    # Read the whole text.\n",
    "    #text = open(path.join(d, 'constitution.txt')).read()\n",
    "    textpos = data[data.Stance == 'agree']\n",
    "    textneg = data[data.Stance == 'unrelated']\n",
    "    \n",
    "    posdata=\"\"\n",
    "    for i in textpos.index.values:\n",
    "        posdata+=textpos['Headline'][i]+\" \"\n",
    "    negdata=\"\"\n",
    "    for i in textneg.index.values:\n",
    "        negdata+=textneg['Headline'][i]+\" \"\n",
    "    \n",
    "    textp = preprocess(posdata)\n",
    "    textp=\" \".join(textp)\n",
    "    textn = preprocess(negdata)\n",
    "    textn=\" \".join(textn)\n",
    "    wordcloudp = WordCloud( stopwords=stop,background_color='white',width=1200,height=1000).generate(textp)\n",
    "    wordcloudn = WordCloud( stopwords=stop,background_color='white', width=1200,height=1000).generate(textn)\n",
    "    image1 = wordcloudp.to_image()\n",
    "    image2= wordcloudn.to_image()\n",
    "    image1.save(\"wordcloup.png\")\n",
    "    image2.save(\"wordcloudn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "stop = stopwords.words('english') + ['and']\n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "\n",
    "  \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "Count=0\n",
    "\n",
    "def tokenize(s):\n",
    "    tokens=tokens_re.findall(s)\n",
    "    return [ x for x in tokens if 'http' not in x and len(x)>1 and x.lower() not in stop]\n",
    " \n",
    "def preprocess(s, lowercase=True):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def collect_pairs(lines):\n",
    "    pair_counter = Counter()\n",
    "    for line in lines:\n",
    "        unique_tokens = sorted(set(line))  # exclude duplicates in same line and sort to ensure one word is always before other\n",
    "        combos = combinations(unique_tokens, 2)\n",
    "        pair_counter += Counter(combos)\n",
    "    return pair_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "createwordcloud(stances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Wordcloud:\n",
    "\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "    #d = path.dirname(__file__)\n",
    "def createwordcloud(words):  \n",
    "    # Read the whole text.\n",
    "    #text = open(path.join(d, 'constitution.txt')).read()\n",
    "    textpos = words[words.Stance == 'agree']\n",
    "    textneg = words[words.Stance == 'unrelated']\n",
    "    \n",
    "    poswords=\"\"\n",
    "    for i in textpos.index.values:\n",
    "        poswords+=textpos['articleBody'][i]+\" \"\n",
    "    negwords=\"\"\n",
    "    for i in textneg.index.values:\n",
    "        negwords+=textneg['articleBody'][i]+\" \"\n",
    "    \n",
    "    textp = preprocess(poswords)\n",
    "    textp=\" \".join(textp)\n",
    "    textn = preprocess(negwords)\n",
    "    textn=\" \".join(textn)\n",
    "    wordcloudp = WordCloud( stopwords=stop,background_color='white',width=1200,height=1000).generate(textp)\n",
    "    wordcloudn = WordCloud( stopwords=stop,background_color='white', width=1200,height=1000).generate(textn)\n",
    "    image1 = wordcloudp.to_image()\n",
    "    image2= wordcloudn.to_image()\n",
    "    image1.save(\"wordcloup-body.png\")\n",
    "    image2.save(\"wordcloudn-body.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "createwordcloud(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
