{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [\"When\",\"they\",\"fought\",\"the\",\"Parisians\",\"the\",\"Greeks\",\"were\",\"outnumbered\",\"because\",\"the\",\"Persians\",\"had\",\"more\",\"men\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.5, 0.029411764705882353, 0.01818181818181818, 0.01818181818181818]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,2,34,55,55]\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = lambda my_list: list(map(lambda x: x ** -1, my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import CFG\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S0 -> NP VP | T B | NP C | S S\n",
    "NP -> D F | D H | I F | NP\n",
    "VP -> L | L NP | L ADJP | VP O\n",
    "ADJP -> I | P I\n",
    "B -> NP VP\n",
    "C -> VP S\n",
    "D -> det\n",
    "F -> n\n",
    "H -> I F\n",
    "I -> adj\n",
    "L -> v\n",
    "O -> T VP\n",
    "P -> adv\n",
    "T -> kon\n",
    "adj  -> 'outnumbered' | 'more'\n",
    "det  -> 'the'\n",
    "kon  -> 'When' | 'because'\n",
    "n  -> 'Parisians' | 'Greeks' | 'Persians' | 'men' | 'they'\n",
    "v  -> 'fought' | 'were' | 'had'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 0))\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tree.read(): expected '(' but got 'S'\n            at index 1.\n                \" S -> NP VP...\"\n                  ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-2ecd9e2459c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mpp\u001b[0m  \u001b[1;33m->\u001b[0m \u001b[1;34m'they'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mv\u001b[0m  \u001b[1;33m->\u001b[0m \u001b[1;34m'fought'\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;34m'were'\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;34m'had'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \"\"\")\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36mfromstring\u001b[1;34m(cls, s, brackets, read_node, read_leaf, node_pattern, leaf_pattern, remove_empty_top_bracketing)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m                     \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mread_leaf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_leaf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sriram\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_parse_error\u001b[1;34m(cls, s, match, expecting)\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\n%s\"%s\"\\n%s^'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[1;31m#////////////////////////////////////////////////////////////\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tree.read(): expected '(' but got 'S'\n            at index 1.\n                \" S -> NP VP...\"\n                  ^"
     ]
    }
   ],
   "source": [
    "from nltk import Tree\n",
    "tree=Tree.fromstring(\"\"\"\n",
    "S -> NP VP | kon NP VP | NP VP S | S S\n",
    "NP -> det n | det adj n | adj n | pp\n",
    "VP -> v | v NP | v ADJP | VP kon VP\n",
    "ADJP -> adj | adv adj\n",
    "adj  -> 'outnumbered' | 'more'\n",
    "det  -> 'the'\n",
    "kon  -> 'When' | 'because'\n",
    "n  -> 'Parisians' | 'Greeks' | 'Persians' | 'men'\n",
    "pp  -> 'they'\n",
    "v  -> 'fought' | 'were' | 'had'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S0 -> NP VP,\n",
       " S0 -> T B,\n",
       " S0 -> NP C,\n",
       " S0 -> S S,\n",
       " NP -> D F,\n",
       " NP -> D H,\n",
       " NP -> I F,\n",
       " NP -> pp,\n",
       " VP -> v,\n",
       " VP -> L NP,\n",
       " VP -> L ADJP,\n",
       " VP -> VP O,\n",
       " ADJP -> adj,\n",
       " ADJP -> P I,\n",
       " B -> NP VP,\n",
       " C -> VP S,\n",
       " D -> det,\n",
       " F -> n,\n",
       " H -> I F,\n",
       " I -> adj,\n",
       " L -> v,\n",
       " O -> T VP,\n",
       " P -> adv,\n",
       " T -> kon,\n",
       " I -> 'outnumbered',\n",
       " I -> 'more',\n",
       " D -> 'the',\n",
       " T -> 'When',\n",
       " T -> 'because',\n",
       " F -> 'Parisians',\n",
       " F -> 'Greeks',\n",
       " F -> 'Persians',\n",
       " F -> 'men',\n",
       " pp -> 'they',\n",
       " v -> 'fought',\n",
       " v -> 'were',\n",
       " v -> 'had',\n",
       " L -> 'fought',\n",
       " L -> 'were',\n",
       " L -> 'had']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_wfst(tokens, grammar):\n",
    "\tnumtokens = len(tokens)\n",
    "\t# fill w/ dots\n",
    "\twfst = [[\".\" for i in range(numtokens+1)] for j in \trange(numtokens+1)]\n",
    "\t#print(wfst)\n",
    "\t# fill in diagonal\n",
    "\tfor i in range(numtokens):\n",
    "\t\tproductions = grammar.productions(rhs=tokens[i])\n",
    "\t\t#print (productions)\n",
    "\t\twfst[14][i] = productions[0].lhs()\n",
    "\treturn wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def complete_wfst(wfst, tokens, trace=True):\n",
    "\tindex = {}\n",
    "\tfor prod in grammar.productions(): #make reverse lookup\n",
    "\t\tindex[prod.rhs()] = prod.lhs()\n",
    "\t#print (index)\n",
    "\tnumtokens = len(tokens)\n",
    "\tfor span in range(2, numtokens+1):\n",
    "\t\tfor start in range(numtokens+1-span): #go down diagonal\n",
    "\t\t\tend = start + span\n",
    "\t\t\tfor mid in range(start+1, end):\n",
    "\t\t\t\tnt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "\t\t\t\tif (nt1,nt2) in index:\n",
    "\t\t\t\t\tif trace:\n",
    "\t\t\t\t\t\tprint (\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % (start, nt1, mid, nt2, end, start, index[(nt1,nt2)], end) )\n",
    "\t\t\t\t\twfst[start][end] = index[(nt1,nt2)]\n",
    "\treturn wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(kon, pp)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfst0[0][1], wfst0[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display(wfst, tokens):\n",
    "\tprint ('\\nWFST ' + ' '.join([(\"%-3d\" %i) for i in range(1, len(wfst))]))\n",
    "\tfor i in range(len(wfst)-1):\n",
    "\t\tprint (\"%d \" % i,end='')\n",
    "\t\tfor j in range(1, len(wfst)):\n",
    "\t\t\tprint (\"%-4s\" % wfst[i][j],end='')\n",
    "\t\tprint(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.productions(rhs='Parisians')[0].lhs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wfst0 = init_wfst(tokens, grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1   2   3   4   5   6   7   8   9   10  11  12  13  14  15 \n",
      "0 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "1 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "2 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "3 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "4 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "5 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "6 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "7 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "8 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "9 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "10 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "11 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "12 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "13 .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "14 n   v   det n   det n   v   adj kon det n   v   adj n   .   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(wfst0,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wfst1=complete_wfst(wfst0,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1   2   3   4   5   6   7   8   9   10  11  12  13  14  15 \n",
      "0 T   .   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "1 .   F   .   .   .   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "2 .   .   L   .   VP  .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "3 .   .   .   D   NP  .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "4 .   .   .   .   F   .   .   .   .   .   .   .   .   .   .   \n",
      "\n",
      "5 .   .   .   .   .   D   NP  .   .   .   .   .   .   .   .   \n",
      "\n",
      "6 .   .   .   .   .   .   F   .   .   .   .   .   .   .   .   \n",
      "\n",
      "7 .   .   .   .   .   .   .   L   .   .   .   .   .   .   .   \n",
      "\n",
      "8 .   .   .   .   .   .   .   .   I   .   .   .   .   .   .   \n",
      "\n",
      "9 .   .   .   .   .   .   .   .   .   T   .   .   .   .   .   \n",
      "\n",
      "10 .   .   .   .   .   .   .   .   .   .   D   NP  .   .   .   \n",
      "\n",
      "11 .   .   .   .   .   .   .   .   .   .   .   F   .   .   .   \n",
      "\n",
      "12 .   .   .   .   .   .   .   .   .   .   .   .   L   .   .   \n",
      "\n",
      "13 .   .   .   .   .   .   .   .   .   .   .   .   .   I   H   \n",
      "\n",
      "14 .   .   .   .   .   .   .   .   .   .   .   .   .   .   F   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(wfst1,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
